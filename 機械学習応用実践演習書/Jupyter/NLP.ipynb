{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "\n",
    "Mecabのインストール (Windows)\n",
    "\n",
    "1. Microsoft Visual C++ 2008 SP1 Redistributable Package x86\n",
    "のインストール\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=5582\n",
    "\n",
    "1. MeCab 64bitのインストール (標準の場所に)\n",
    "https://github.com/ikegami-yukino/mecab/releases\n",
    "\n",
    "1. インストール後のMecab\\binにPATHを通す\n",
    "\n",
    "1. パッケージのダウンロード\n",
    "https://pypi.python.org/pypi/mecab-python-windows\n",
    "\n",
    "1. Anaconda Promptを開き、MeCabパッケージの場所で\n",
    "pip install mecab-python-windows\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "要素\tヨウソ\t要素\t名詞-一般\t\t\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "として\tトシテ\tとして\t助詞-格助詞-連語\t\t\n",
      "もつ\tモツ\tもつ\t動詞-自立\t五段・タ行\t基本形\n",
      "製品\tセイヒン\t製品\t名詞-一般\t\t\n",
      "や\tヤ\tや\t助詞-並立助詞\t\t\n",
      "サービス\tサービス\tサービス\t名詞-サ変接続\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "設計\tセッケイ\t設計\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "実装\tジッソウ\t実装\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "評価\tヒョウカ\t評価\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "できる\tデキル\tできる\t動詞-自立\t一段\t基本形\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "者\tシャ\t者\t名詞-接尾-一般\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "育成\tイクセイ\t育成\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "目的\tモクテキ\t目的\t名詞-一般\t\t\n",
      "と\tト\tと\t助詞-格助詞-一般\t\t\n",
      "し\tシ\tする\t動詞-自立\tサ変・スル\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "sent = \"機械学習を要素技術としてもつ製品やサービスの設計・実装・評価ができる技術者の育成を目的とします。\"\n",
    "print(m.parse(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['機械', '学習', 'を', '要素', '技術', 'として', 'もつ', '製品', 'や', 'サービス', 'の', '設計', '・', '実装', '・', '評価', 'が', 'できる', '技術', '者', 'の', '育成', 'を', '目的', 'と', 'し', 'ます', '。']\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "print(m.parse(sent).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vecを用いた単語の数値ベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備\n",
    "\n",
    "gensimのインストール\n",
    "\n",
    "1. conda install gensim\n",
    "\n",
    "word2vecのWikipediaでの学習済みモデルをダウンロード・展開し、binファイルをカレントディレクトリに置いておきます。\n",
    "\n",
    "http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\usr\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html)の使い方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('entity_vector.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['機械学習'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('データマイニング', 0.6891660690307617),\n",
       " ('[ハードウェアマルチスレッディング]', 0.6831626892089844),\n",
       " ('インフォメーションテクノロジー', 0.6759535074234009),\n",
       " ('[クエリ最適化]', 0.6739107966423035),\n",
       " ('[走査型プローブ顕微鏡]', 0.6723648905754089),\n",
       " ('[ファジィ制御]', 0.6713464260101318),\n",
       " ('[ブレッドボード]', 0.6706169247627258),\n",
       " ('[静的コード解析]', 0.6697294116020203),\n",
       " ('[IDEF1X]', 0.6688075065612793),\n",
       " ('[並行計算]', 0.6687707304954529)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('機械学習')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('国王', 0.7291181087493896),\n",
       " ('は王', 0.7007638812065125),\n",
       " ('王妃', 0.6984109282493591),\n",
       " ('[王]', 0.6832639575004578),\n",
       " ('大王', 0.6761249303817749),\n",
       " ('女王', 0.6732375621795654),\n",
       " ('王子', 0.6688757538795471),\n",
       " ('上王', 0.662589430809021),\n",
       " ('[ポルトガル君主一覧]', 0.6567022800445557),\n",
       " ('[イングランド君主一覧]', 0.6522811651229858)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['女性','王'], negative=['男性'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('パリ', 0.7462971210479736),\n",
       " ('[パリ]', 0.6993756294250488),\n",
       " ('ベルリン', 0.6419283747673035),\n",
       " ('ロンドン', 0.6390187740325928),\n",
       " ('ミラノ', 0.6374871730804443),\n",
       " ('ウィーン', 0.6211003065109253),\n",
       " ('ブリュッセル', 0.612484335899353),\n",
       " ('ミュンヘン', 0.6093115210533142),\n",
       " ('ハンブルク', 0.5993486642837524),\n",
       " ('[リヨン]', 0.5960404276847839)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['フランス','東京'], negative=['日本'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Doc2Vec\n",
    "\n",
    "文や文章をベクトル化して、類似度計算を可能にします。\n",
    "\n",
    "参考サイト\n",
    "\n",
    "[Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル](https://deepage.net/machine_learning/2017/01/08/doc2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.23748838901519775),\n",
       " (6, 0.09878705441951752),\n",
       " (1, 0.0795365646481514),\n",
       " (2, 0.06770960986614227),\n",
       " (5, 0.04849783331155777),\n",
       " (3, 0.04045093059539795),\n",
       " (0, 0.006615493446588516)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "sentences = [\n",
    "    \"２時にアラームをセット\",\n",
    "    \"アラームを３時に設定\",\n",
    "    \"５時になったら知らせて\",\n",
    "    \"アラームをセット\",\n",
    "    \"３０分後に起こして\",\n",
    "    \"２時に新大阪に着きたい\",\n",
    "    \"乗換案内\",\n",
    "    \"京都から東京までの新幹線\",\n",
    "]\n",
    "\n",
    "# 空のリストを作成（学習データとなる各文書を格納）\n",
    "X = []\n",
    "for s, t in zip(sentences, range(len(sentences))):\n",
    "    X.append(TaggedDocument(words=m.parse(s).split(), tags=[t]))   \n",
    "\n",
    "# 学習\n",
    "# documents:学習データ（TaggedDocumentのリスト）\n",
    "# min_count: 学習に使用する単語の最低出現回数\n",
    "# dm:学習モデル 0:DBOW, 1:DM（デフォルト)\n",
    "model = Doc2Vec(documents=X, min_count=1, dm=1)\n",
    " \n",
    "# 学習したモデルを保存\n",
    "model.save('doc2vec.model')\n",
    " \n",
    "model.docvecs.most_similar([7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
