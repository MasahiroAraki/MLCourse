{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Project - Building NER Taggers.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9eqLTgATnKv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasahiroAraki/MLCourse/blob/master/Python/13_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN5H-fc-MLqO"
      },
      "source": [
        "# 第13章 系列データの識別\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnIprN46MCfx"
      },
      "source": [
        "このnotebookは、[ODSC India 2019 - NLP Workshop](https://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module03%20-%20Text%20Understanding/Project%20-%20Building%20NER%20Taggers.ipynb) の資料を参考にしました。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVRfi2ttRnGc"
      },
      "source": [
        "データセットをダウンロードします。このデータは、 GMB(Groningen Meaning Bank) コーパス（英文）に品詞タグと固有表現タグを付けたものです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20SOlMYSTiB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e7d90e-85a9-47af-a792-b3b9ecb3db2d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2008%20-%20Project%206%20-%20Build%20your%20NER%20Tagger/ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   Sentence #  47959 non-null    object\n",
            " 1   Word        1048575 non-null  object\n",
            " 2   POS         1048575 non-null  object\n",
            " 3   Tag         1048575 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 32.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7ZvE70kSMkZ"
      },
      "source": [
        "文番号(sentence #) が文の先頭単語にしか付いていないので、同一文中の後続単語にも同じ番号を付与します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHtZvIgdTiB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290efe00-5ac4-4ae6-dc9d-6ecd5d1c5643"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   Sentence #  1048575 non-null  object\n",
            " 1   Word        1048575 non-null  object\n",
            " 2   POS         1048575 non-null  object\n",
            " 3   Tag         1048575 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 32.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAeMEiV3Sh_q"
      },
      "source": [
        "データの一部を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or8Tfxl-TiCB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9cc9e0ee-3296-4b76-da73-08b17725e5be"
      },
      "source": [
        "df[:100].T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sentence #</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>...</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 3</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 4</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Sentence: 5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>troops</td>\n",
              "      <td>from</td>\n",
              "      <td>that</td>\n",
              "      <td>country</td>\n",
              "      <td>.</td>\n",
              "      <td>Families</td>\n",
              "      <td>of</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>killed</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>conflict</td>\n",
              "      <td>joined</td>\n",
              "      <td>the</td>\n",
              "      <td>protesters</td>\n",
              "      <td>who</td>\n",
              "      <td>carried</td>\n",
              "      <td>banners</td>\n",
              "      <td>with</td>\n",
              "      <td>such</td>\n",
              "      <td>slogans</td>\n",
              "      <td>...</td>\n",
              "      <td>Parliament</td>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "      <td>rally</td>\n",
              "      <td>in</td>\n",
              "      <td>Hyde</td>\n",
              "      <td>Park</td>\n",
              "      <td>.</td>\n",
              "      <td>Police</td>\n",
              "      <td>put</td>\n",
              "      <td>the</td>\n",
              "      <td>number</td>\n",
              "      <td>of</td>\n",
              "      <td>marchers</td>\n",
              "      <td>at</td>\n",
              "      <td>10,000</td>\n",
              "      <td>while</td>\n",
              "      <td>organizers</td>\n",
              "      <td>claimed</td>\n",
              "      <td>it</td>\n",
              "      <td>was</td>\n",
              "      <td>1,00,000</td>\n",
              "      <td>.</td>\n",
              "      <td>The</td>\n",
              "      <td>protest</td>\n",
              "      <td>comes</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>eve</td>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>annual</td>\n",
              "      <td>conference</td>\n",
              "      <td>of</td>\n",
              "      <td>Britain</td>\n",
              "      <td>'s</td>\n",
              "      <td>ruling</td>\n",
              "      <td>Labor</td>\n",
              "      <td>Party</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POS</th>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>VBP</td>\n",
              "      <td>VBN</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>TO</td>\n",
              "      <td>VB</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>CC</td>\n",
              "      <td>VB</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>.</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>VBN</td>\n",
              "      <td>IN</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>VBD</td>\n",
              "      <td>DT</td>\n",
              "      <td>NNS</td>\n",
              "      <td>WP</td>\n",
              "      <td>VBD</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NNS</td>\n",
              "      <td>...</td>\n",
              "      <td>NN</td>\n",
              "      <td>TO</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>.</td>\n",
              "      <td>NNS</td>\n",
              "      <td>VBD</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>VBD</td>\n",
              "      <td>PRP</td>\n",
              "      <td>VBD</td>\n",
              "      <td>CD</td>\n",
              "      <td>.</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>IN</td>\n",
              "      <td>DT</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>DT</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NN</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>POS</td>\n",
              "      <td>VBG</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tag</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>...</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>I-geo</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-org</td>\n",
              "      <td>I-org</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0            1   ...           98           99\n",
              "Sentence #  Sentence: 1  Sentence: 1  ...  Sentence: 5  Sentence: 5\n",
              "Word          Thousands           of  ...        Party           in\n",
              "POS                 NNS           IN  ...          NNP           IN\n",
              "Tag                   O            O  ...        I-org            O\n",
              "\n",
              "[4 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSjjXerNTgBO"
      },
      "source": [
        "文数、異なり単語数、品詞数、BIOタグ数を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh8lDQ1VTiCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a56aea4-4ed3-48cf-c067-b481a8980134"
      },
      "source": [
        "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 35178, 42, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HELZgi7WT_sR"
      },
      "source": [
        "固有表現タグの分布を確認します。固有表現の種別は以下のカテゴリを表します。\n",
        "\n",
        "* geo : 地理的実体\n",
        "* org : 組織\n",
        "* per : 人\n",
        "* gpe : 国名等\n",
        "* tim : 日時\n",
        "* art : 人工物\n",
        "* eve : イベント\n",
        "* nat : 自然現象\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYkVvfvJTiCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291e5be2-2d71-4dc4-afd3-99ca2a876fc4"
      },
      "source": [
        "df.Tag.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3joYxUObdig"
      },
      "source": [
        "文中から素性値を求めるメソッドを定義します。素性値は以下のもので、先頭単語と末尾単語のみ前後の単語に関する処理が異なります。\n",
        "\n",
        "* 小文字に変換した単語の見出し表記\n",
        "* 単語の末尾3文字\n",
        "* 単語の末尾2文字\n",
        "* すべて大文字、先頭文字のみ大文字、数値、品詞の情報"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a8sFLVuTiCR"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "            'BOS' : False,\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "            'EOS' : False\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdvlZtXTlWdp"
      },
      "source": [
        "(単語, 品詞, NEタグ) のタプルのリストからなる文のリスト (sentences) を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEz01_S8TiCV"
      },
      "source": [
        "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
        "                                                   s['POS'].values.tolist(), \n",
        "                                                   s['Tag'].values.tolist())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui1owUAVTiCa"
      },
      "source": [
        "grouped_df = df.groupby('Sentence #').apply(agg_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCZC4fFbTiCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8469225d-ddd0-4387-e3c9-d74dbef09b00"
      },
      "source": [
        "print(grouped_df[grouped_df.index == 'Sentence: 1'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[list([('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0wUFmfmTiCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7c87f1-274d-4373-ec32-406b1e6acdb2"
      },
      "source": [
        "grouped_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDlJKsDUTiCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a89087-a020-4e52-86a9-8fa27ef1e870"
      },
      "source": [
        "sentences = [s for s in grouped_df]\n",
        "sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'NNS', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('demonstrators', 'NNS', 'O'),\n",
              " ('have', 'VBP', 'O'),\n",
              " ('marched', 'VBN', 'O'),\n",
              " ('through', 'IN', 'O'),\n",
              " ('London', 'NNP', 'B-geo'),\n",
              " ('to', 'TO', 'O'),\n",
              " ('protest', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('war', 'NN', 'O'),\n",
              " ('in', 'IN', 'O'),\n",
              " ('Iraq', 'NNP', 'B-geo'),\n",
              " ('and', 'CC', 'O'),\n",
              " ('demand', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('withdrawal', 'NN', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('British', 'JJ', 'B-gpe'),\n",
              " ('troops', 'NNS', 'O'),\n",
              " ('from', 'IN', 'O'),\n",
              " ('that', 'DT', 'O'),\n",
              " ('country', 'NN', 'O'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTsgWN4logQ"
      },
      "source": [
        "文の一部を取り出して、素性値の計算がうまく行われているか確認します。一部を取り出しているので、文頭・文末を表すBOS, EOSの値は本来の値とは異なります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgo0w5ThTiCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c82fa28-79a4-4eb0-bdfa-deca1700ae79"
      },
      "source": [
        "sent2features(sentences[0][5:7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'+1:postag': 'NNP',\n",
              "  '+1:postag[:2]': 'NN',\n",
              "  '+1:word.istitle()': True,\n",
              "  '+1:word.isupper()': False,\n",
              "  '+1:word.lower()': 'london',\n",
              "  'BOS': True,\n",
              "  'EOS': False,\n",
              "  'bias': 1.0,\n",
              "  'postag': 'IN',\n",
              "  'postag[:2]': 'IN',\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': False,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': 'through',\n",
              "  'word[-2:]': 'gh',\n",
              "  'word[-3:]': 'ugh'},\n",
              " {'-1:postag': 'IN',\n",
              "  '-1:postag[:2]': 'IN',\n",
              "  '-1:word.istitle()': False,\n",
              "  '-1:word.isupper()': False,\n",
              "  '-1:word.lower()': 'through',\n",
              "  'BOS': False,\n",
              "  'EOS': True,\n",
              "  'bias': 1.0,\n",
              "  'postag': 'NNP',\n",
              "  'postag[:2]': 'NN',\n",
              "  'word.isdigit()': False,\n",
              "  'word.istitle()': True,\n",
              "  'word.isupper()': False,\n",
              "  'word.lower()': 'london',\n",
              "  'word[-2:]': 'on',\n",
              "  'word[-3:]': 'don'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08hbOg30mJdq"
      },
      "source": [
        "正解ラベルを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Cy6Fd3TiCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d08967-3b30-480f-cf0a-d863739fd7f3"
      },
      "source": [
        "sent2labels(sentences[0][5:7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-geo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adx04n43TiCv"
      },
      "source": [
        "データセットを学習用と評価用に分割します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpp1oPhGTiCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b3522f-2244-4348-c206-7e68a8442b6f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([sent2features(s) for s in sentences], dtype=object)\n",
        "y = np.array([sent2labels(s) for s in sentences], dtype=object)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35969,), (11990,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B56GXmxsTiC1"
      },
      "source": [
        "[CRFsuite (python-crfsuite)](https://github.com/scrapinghub/python-crfsuite) を用いて学習します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlgimPwTTiC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f0ccdb-024c-4c40-bc88-cbfced944509"
      },
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oYdt58KnOSK"
      },
      "source": [
        "CRFのインスタンスを作成します。ハイパーパラメータの意味を以下に示します。\n",
        "\n",
        "* algorithim: 最適化アルゴリズムの指定\n",
        "* c1 : L1正則化項の重み\n",
        "* c2 : L2正則化項の重み\n",
        "* max_iterations: 繰り返し回数の上限\n",
        "* all_possible_transitions : 学習データに出現しないラベルの遷移も素性とする\n",
        "* verbose : 学習過程の詳細な情報を出力\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUMlk4QFTiDA"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "\n",
        "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
        "                           c1=0.1,\n",
        "                           c2=0.1,\n",
        "                           max_iterations=50,\n",
        "                           all_possible_transitions=True,\n",
        "                           verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hXTph2l8TiDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae92814-09cf-462d-a440-e691a05511da"
      },
      "source": [
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading training data to CRFsuite: 100%|██████████| 35969/35969 [00:10<00:00, 3465.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Feature generation\n",
            "type: CRF1d\n",
            "feature.minfreq: 0.000000\n",
            "feature.possible_states: 0\n",
            "feature.possible_transitions: 1\n",
            "0....1....2....3....4....5....6....7....8....9....10\n",
            "Number of features: 133645\n",
            "Seconds required: 1.839\n",
            "\n",
            "L-BFGS optimization\n",
            "c1: 0.100000\n",
            "c2: 0.100000\n",
            "num_memories: 6\n",
            "max_iterations: 50\n",
            "epsilon: 0.000010\n",
            "stop: 10\n",
            "delta: 0.000010\n",
            "linesearch: MoreThuente\n",
            "linesearch.max_iterations: 20\n",
            "\n",
            "Iter 1   time=3.29  loss=1263996.98 active=132653 feature_norm=1.00\n",
            "Iter 2   time=3.43  loss=994013.75 active=131310 feature_norm=4.42\n",
            "Iter 3   time=1.70  loss=776364.07 active=125987 feature_norm=3.87\n",
            "Iter 4   time=8.52  loss=421961.16 active=127027 feature_norm=3.24\n",
            "Iter 5   time=1.69  loss=354425.51 active=129045 feature_norm=4.04\n",
            "Iter 6   time=1.74  loss=260017.69 active=122707 feature_norm=6.18\n",
            "Iter 7   time=1.69  loss=219836.67 active=115755 feature_norm=7.98\n",
            "Iter 8   time=1.69  loss=196203.95 active=110953 feature_norm=8.86\n",
            "Iter 9   time=1.84  loss=177983.48 active=106540 feature_norm=10.22\n",
            "Iter 10  time=1.71  loss=159716.67 active=102765 feature_norm=11.88\n",
            "Iter 11  time=1.72  loss=147410.63 active=101230 feature_norm=13.17\n",
            "Iter 12  time=1.70  loss=139159.86 active=100097 feature_norm=14.20\n",
            "Iter 13  time=1.70  loss=128009.09 active=95826 feature_norm=17.09\n",
            "Iter 14  time=1.70  loss=116836.68 active=94912 feature_norm=18.35\n",
            "Iter 15  time=1.70  loss=109458.24 active=93047 feature_norm=20.44\n",
            "Iter 16  time=1.71  loss=104553.72 active=91726 feature_norm=22.35\n",
            "Iter 17  time=1.70  loss=99672.55 active=90893 feature_norm=24.22\n",
            "Iter 18  time=1.71  loss=94965.86 active=90032 feature_norm=26.33\n",
            "Iter 19  time=1.71  loss=87964.23 active=87334 feature_norm=30.97\n",
            "Iter 20  time=1.73  loss=82534.81 active=86869 feature_norm=35.92\n",
            "Iter 21  time=1.74  loss=78466.74 active=86706 feature_norm=39.07\n",
            "Iter 22  time=1.75  loss=74354.21 active=85261 feature_norm=44.21\n",
            "Iter 23  time=1.76  loss=70888.87 active=84840 feature_norm=46.81\n",
            "Iter 24  time=1.74  loss=67951.44 active=83924 feature_norm=50.54\n",
            "Iter 25  time=1.71  loss=64059.22 active=82223 feature_norm=57.45\n",
            "Iter 26  time=1.71  loss=62254.99 active=81281 feature_norm=64.41\n",
            "Iter 27  time=1.73  loss=59559.88 active=81539 feature_norm=66.15\n",
            "Iter 28  time=1.72  loss=58040.78 active=81209 feature_norm=68.79\n",
            "Iter 29  time=1.71  loss=55491.04 active=80074 feature_norm=74.58\n",
            "Iter 30  time=1.72  loss=53454.84 active=79699 feature_norm=80.08\n",
            "Iter 31  time=1.71  loss=51628.64 active=79687 feature_norm=83.96\n",
            "Iter 32  time=1.70  loss=49830.30 active=78886 feature_norm=89.46\n",
            "Iter 33  time=1.73  loss=47970.60 active=77823 feature_norm=97.18\n",
            "Iter 34  time=1.73  loss=46489.84 active=76469 feature_norm=103.51\n",
            "Iter 35  time=1.72  loss=44888.17 active=76242 feature_norm=110.62\n",
            "Iter 36  time=1.68  loss=43195.77 active=75223 feature_norm=120.46\n",
            "Iter 37  time=1.69  loss=41791.67 active=73883 feature_norm=131.62\n",
            "Iter 38  time=1.75  loss=40489.91 active=73540 feature_norm=139.62\n",
            "Iter 39  time=1.71  loss=39378.42 active=73197 feature_norm=148.07\n",
            "Iter 40  time=1.69  loss=38719.61 active=71284 feature_norm=171.66\n",
            "Iter 41  time=1.68  loss=37542.96 active=71901 feature_norm=173.23\n",
            "Iter 42  time=1.73  loss=37364.10 active=71990 feature_norm=174.29\n",
            "Iter 43  time=1.68  loss=36862.19 active=71621 feature_norm=178.48\n",
            "Iter 44  time=1.67  loss=36426.44 active=70833 feature_norm=190.17\n",
            "Iter 45  time=1.70  loss=35844.03 active=70965 feature_norm=191.47\n",
            "Iter 46  time=1.72  loss=35673.48 active=70953 feature_norm=192.47\n",
            "Iter 47  time=1.83  loss=35170.23 active=68816 feature_norm=199.29\n",
            "Iter 48  time=1.75  loss=35025.42 active=69134 feature_norm=197.57\n",
            "Iter 49  time=1.71  loss=34917.53 active=69273 feature_norm=197.44\n",
            "Iter 50  time=1.70  loss=34853.16 active=68991 feature_norm=197.51\n",
            "L-BFGS terminated with the maximum number of iterations\n",
            "Total seconds required for training: 95.949\n",
            "\n",
            "Storing the model\n",
            "Number of active features: 68991 (133645)\n",
            "Number of active attributes: 34830 (90250)\n",
            "Number of active labels: 17 (17)\n",
            "Writing labels\n",
            "Writing attributes\n",
            "Writing feature references for transitions\n",
            "Writing feature references for attributes\n",
            "Seconds required: 0.039\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=50,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4ITrtJRTiDi"
      },
      "source": [
        "まず評価用データの先頭の文で妥当な結果が出ていることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQqRw060TiDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31f0f38-89ec-4860-ca64-470f11155a17"
      },
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "print(y_pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI25InSYTiDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a70a9c7-d32b-4e0e-fe58-e278eb9f7186"
      },
      "source": [
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhjilYi9ogu5"
      },
      "source": [
        "O以外のタグで性能評価を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7lIbMwpTiDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fe5cfd-493f-4551-df19-fe640a4fe327"
      },
      "source": [
        "from sklearn_crfsuite import metrics as crf_metrics\n",
        "\n",
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-org       0.81      0.73      0.77      5116\n",
            "       B-per       0.85      0.83      0.84      4239\n",
            "       I-per       0.86      0.90      0.88      4273\n",
            "       B-geo       0.86      0.92      0.89      9403\n",
            "       I-geo       0.82      0.80      0.81      1826\n",
            "       B-tim       0.93      0.88      0.91      5095\n",
            "       I-org       0.81      0.80      0.80      4195\n",
            "       B-gpe       0.98      0.94      0.96      3961\n",
            "       I-tim       0.84      0.80      0.82      1604\n",
            "       B-nat       0.67      0.25      0.37        55\n",
            "       B-eve       0.48      0.33      0.39        80\n",
            "       B-art       0.31      0.11      0.16       102\n",
            "       I-art       0.10      0.02      0.04        90\n",
            "       I-eve       0.40      0.19      0.26        74\n",
            "       I-gpe       0.95      0.50      0.65        36\n",
            "       I-nat       1.00      0.22      0.36        18\n",
            "\n",
            "   micro avg       0.86      0.85      0.86     40167\n",
            "   macro avg       0.73      0.58      0.62     40167\n",
            "weighted avg       0.86      0.85      0.85     40167\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g1MNOboomqs"
      },
      "source": [
        "## 課題\n",
        "\n",
        "効果の高そうな素性をいくつか当たりを付けて、その素性を削除した条件で実験を行うことで、素性の有効性を評価する実験を行ってください。"
      ]
    }
  ]
}