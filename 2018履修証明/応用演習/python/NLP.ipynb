{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "項目\n",
    "\n",
    " 1. 形態素解析\n",
    " 2. 単語のベクトル化\n",
    " 3. 文のベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "\n",
    "日本語文字列を単語列に分割する処理です。形態素解析器Mecabがよく使われており、\n",
    "新語の解析が必要な場合は、追加の辞書として[NEologd](https://github.com/neologd/mecab-ipadic-neologd)が使われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecabのインストール (Windows)\n",
    "\n",
    "1. Microsoft Visual C++ 2008 SP1 Redistributable Package x86\n",
    "のインストール\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=5582\n",
    "\n",
    "1. MeCab 64bitのインストール (標準の場所に)\n",
    "https://github.com/ikegami-yukino/mecab/releases\n",
    "\n",
    "1. インストール後のMecab\\binにPATHを通す\n",
    "\n",
    "1. パッケージのダウンロード\n",
    "https://pypi.python.org/pypi/mecab-python-windows\n",
    "\n",
    "1. Anaconda Promptを開き、MeCabパッケージの場所で\n",
    "pip install mecab-python-windows\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "要素\tヨウソ\t要素\t名詞-一般\t\t\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "として\tトシテ\tとして\t助詞-格助詞-連語\t\t\n",
      "もつ\tモツ\tもつ\t動詞-自立\t五段・タ行\t基本形\n",
      "製品\tセイヒン\t製品\t名詞-一般\t\t\n",
      "や\tヤ\tや\t助詞-並立助詞\t\t\n",
      "サービス\tサービス\tサービス\t名詞-サ変接続\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "設計\tセッケイ\t設計\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "実装\tジッソウ\t実装\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "評価\tヒョウカ\t評価\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "できる\tデキル\tできる\t動詞-自立\t一段\t基本形\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "者\tシャ\t者\t名詞-接尾-一般\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "育成\tイクセイ\t育成\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "目的\tモクテキ\t目的\t名詞-一般\t\t\n",
      "と\tト\tと\t助詞-格助詞-一般\t\t\n",
      "し\tシ\tする\t動詞-自立\tサ変・スル\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "sent = \"機械学習を要素技術としてもつ製品やサービスの設計・実装・評価ができる技術者の育成を目的とします。\"\n",
    "print(m.parse(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語分割の情報だけが必要な場合は、以下の引数で解析器を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['機械', '学習', 'を', '要素', '技術', 'として', 'もつ', '製品', 'や', 'サービス', 'の', '設計', '・', '実装', '・', '評価', 'が', 'できる', '技術', '者', 'の', '育成', 'を', '目的', 'と', 'し', 'ます', '。']\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "print(m.parse(sent).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vecを用いた単語の数値ベクトル化\n",
    "\n",
    "最も単純に単語を特徴ベクトルに変換する方法はone-hot encodingです。\n",
    "しかしこの方法では、\n",
    "\n",
    " 1. 特徴ベクトルの次元数が単語の種類数となり、大きくなりすぎる\n",
    " 2. 全ての単語の距離が等距離となり、単語の意味の近さが表現できない\n",
    "\n",
    "という問題点があります。\n",
    "\n",
    "そこで、一般に数万次元からなるone-hotベクトルを100～200次元程度の密な（値を持つ次元の数が多い）ベクトルに変換し情報圧縮を行います。圧縮はニューラルネットワークを用いて前後の単語から対象単語を予測するように学習させることによって行い、この操作をword2vecと呼びます。\n",
    "\n",
    "参考サイト  \n",
    "[Word2Vec：発明した本人も驚く単語ベクトルの驚異的な力](https://deepage.net/bigdata/machine_learning/2016/09/02/word2vec_power_of_word_vector.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備\n",
    "\n",
    "1. Anaconda Navigatorからgensimをインストール\n",
    "\n",
    "2. word2vecのWikipediaでの学習済みモデルをダウンロード・展開し、entity_vector.model.binファイルをカレントディレクトリに置いておきます。\n",
    "http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 警告の表示を停止\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html)の使い方\n",
    "\n",
    "単語とベクトルの対応を記録しておけるデータ構造であるKeyedVectorsを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('entity_vector.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語ベクトルの空間で、意味の近いものを求めてみます。\n",
    "\n",
    "台風 地震 猛暑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('酷暑', 0.821641206741333),\n",
       " ('豪雪', 0.7480301856994629),\n",
       " ('大雪', 0.7443932294845581),\n",
       " ('寒波', 0.729661762714386),\n",
       " ('晴天', 0.7281033992767334),\n",
       " ('長雨', 0.7198165655136108),\n",
       " ('曇天', 0.7107530236244202),\n",
       " ('少雨', 0.7036926746368408),\n",
       " ('暴風雪', 0.7032896876335144),\n",
       " ('雷雨', 0.7019506096839905)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('猛暑')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトルの引き算を行うことで、関係を抽出することができます。たとえば、「パリ」から「フランス」を引き算することで「首都」という関係が得られたと考えられるので、「日本」にこの「首都」という関係を足すと、「東京」が得られると期待できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[日本]', 0.6431803703308105),\n",
       " ('東京', 0.6326844692230225),\n",
       " ('[東京]', 0.6148374080657959),\n",
       " ('日本国内', 0.5847295522689819),\n",
       " ('大阪', 0.5656222105026245),\n",
       " ('都内', 0.5597203373908997),\n",
       " ('東京都内', 0.5482653975486755),\n",
       " ('[大阪]', 0.5426324605941772),\n",
       " ('神戸', 0.520367443561554),\n",
       " ('[横浜]', 0.5199853181838989)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['パリ','日本'], negative=['フランス'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('焼き肉', 0.5954942107200623),\n",
       " ('うどん', 0.5942089557647705),\n",
       " ('コロッケ', 0.5901445150375366),\n",
       " ('牛丼', 0.5884590148925781),\n",
       " ('カツ', 0.5824934840202332),\n",
       " ('ネギ', 0.5817806720733643),\n",
       " ('おでん', 0.5800793170928955),\n",
       " ('パフェ', 0.5788909196853638),\n",
       " ('おにぎり', 0.5777252912521362),\n",
       " ('焼肉', 0.5764982104301453)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['たこ焼き','香川'], negative=['大阪'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Doc2Vec\n",
    "\n",
    "文や文章をベクトル化して、類似度計算を可能にします。\n",
    "\n",
    "参考サイト  \n",
    "[Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル](https://deepage.net/machine_learning/2017/01/08/doc2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.18761107325553894),\n",
       " (3, 0.14787708222866058),\n",
       " (7, 0.03507033735513687),\n",
       " (8, 0.0038338135927915573),\n",
       " (0, -0.006937611848115921),\n",
       " (1, -0.04006919264793396),\n",
       " (4, -0.05067012459039688),\n",
       " (6, -0.22737416625022888)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "sentences = [\n",
    "    \"２時にアラームをセット\",\n",
    "    \"アラームを３時に設定\",\n",
    "    \"５時になったら知らせて\",\n",
    "    \"アラームを使いたい\",\n",
    "    \"３０分後に起こして\",\n",
    "    \"２時に京都に着きたい\",\n",
    "    \"乗換案内を起動\",\n",
    "    \"京都から東京までの新幹線\",\n",
    "    \"東京行きの最終電車\",\n",
    "]\n",
    "\n",
    "# 空のリストを作成（学習データとなる各文書を格納）\n",
    "X = []\n",
    "for s, t in zip(sentences, range(len(sentences))):\n",
    "    X.append(TaggedDocument(words=m.parse(s).split(), tags=[t]))   \n",
    "\n",
    "# 学習\n",
    "# documents:学習データ（TaggedDocumentのリスト）\n",
    "# min_count: 学習に使用する単語の最低出現回数\n",
    "# dm:学習モデル 0:DBOW, 1:DM（デフォルト)\n",
    "model2 = Doc2Vec(documents=X, min_count=1, dm=1)\n",
    " \n",
    "# 学習したモデルを保存\n",
    "model2.save('doc2vec.model')\n",
    "\n",
    "# 検索\n",
    "model2.docvecs.most_similar([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語情報の平均で文ベクトルを求める\n",
    "\n",
    "word2vecの値を平均して文ベクトルを求めてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dim = 200 #単語ベクトルの次元数\n",
    "X2 = [] #文ベクトル\n",
    "for s in sentences:\n",
    "    words = m.parse(s).split()\n",
    "    sv = np.zeros(dim)\n",
    "    for w in words:\n",
    "        sv += model.get_vector(w)\n",
    "    X2.append(sv/len(s)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コサイン類似度の大きさで文の近さを計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target =アラームを３時に設定\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9292629363044977, '２時にアラームをセット'],\n",
       " [0.7704846422682846, '２時に京都に着きたい'],\n",
       " [0.7513586400491811, '５時になったら知らせて'],\n",
       " [0.7027351892829492, '３０分後に起こして'],\n",
       " [0.6952332890270726, '乗換案内を起動'],\n",
       " [0.5881262385366202, 'アラームを使いたい'],\n",
       " [0.5749803300453311, '京都から東京までの新幹線'],\n",
       " [0.5045383684628988, '東京行きの最終電車']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 1\n",
    "result = []\n",
    "for i in range(len(X2)):\n",
    "    s = sentences[i]\n",
    "    cos_sim = np.dot(X2[target], X2[i]) / (np.linalg.norm(X2[target]) * np.linalg.norm(X2[i]))\n",
    "    if i != target:\n",
    "        result.append([cos_sim, s])\n",
    "print('target ='+sentences[target])\n",
    "sorted(result, reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
