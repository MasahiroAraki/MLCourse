{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "項目\n",
    "\n",
    " 1. 形態素解析\n",
    " 2. 単語のベクトル化\n",
    " 3. 文のベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "\n",
    "日本語文字列を単語列に分割する処理です。形態素解析器Mecabがよく使われており、\n",
    "新語の解析が必要な場合は、追加の辞書としてNeologd(https://github.com/neologd/mecab-ipadic-neologd)が\n",
    "使われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecabのインストール (Windows)\n",
    "\n",
    "1. Microsoft Visual C++ 2008 SP1 Redistributable Package x86\n",
    "のインストール\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=5582\n",
    "\n",
    "1. MeCab 64bitのインストール (標準の場所に)\n",
    "https://github.com/ikegami-yukino/mecab/releases\n",
    "\n",
    "1. インストール後のMecab\\binにPATHを通す\n",
    "\n",
    "1. パッケージのダウンロード\n",
    "https://pypi.python.org/pypi/mecab-python-windows\n",
    "\n",
    "1. Anaconda Promptを開き、MeCabパッケージの場所で\n",
    "pip install mecab-python-windows\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "要素\tヨウソ\t要素\t名詞-一般\t\t\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "として\tトシテ\tとして\t助詞-格助詞-連語\t\t\n",
      "もつ\tモツ\tもつ\t動詞-自立\t五段・タ行\t基本形\n",
      "製品\tセイヒン\t製品\t名詞-一般\t\t\n",
      "や\tヤ\tや\t助詞-並立助詞\t\t\n",
      "サービス\tサービス\tサービス\t名詞-サ変接続\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "設計\tセッケイ\t設計\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "実装\tジッソウ\t実装\t名詞-サ変接続\t\t\n",
      "・\t・\t・\t記号-一般\t\t\n",
      "評価\tヒョウカ\t評価\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "できる\tデキル\tできる\t動詞-自立\t一段\t基本形\n",
      "技術\tギジュツ\t技術\t名詞-一般\t\t\n",
      "者\tシャ\t者\t名詞-接尾-一般\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "育成\tイクセイ\t育成\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "目的\tモクテキ\t目的\t名詞-一般\t\t\n",
      "と\tト\tと\t助詞-格助詞-一般\t\t\n",
      "し\tシ\tする\t動詞-自立\tサ変・スル\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "sent = \"機械学習を要素技術としてもつ製品やサービスの設計・実装・評価ができる技術者の育成を目的とします。\"\n",
    "print(m.parse(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語分割の情報だけが必要な場合は、以下の引数で解析器を呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['機械', '学習', 'を', '要素', '技術', 'として', 'もつ', '製品', 'や', 'サービス', 'の', '設計', '・', '実装', '・', '評価', 'が', 'できる', '技術', '者', 'の', '育成', 'を', '目的', 'と', 'し', 'ます', '。']\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "print(m.parse(sent).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vecを用いた単語の数値ベクトル化\n",
    "\n",
    "最も単純に単語を特徴ベクトルに変換する方法はone-hot encodingです。\n",
    "しかしこの方法では、(1)特徴ベクトルの次元数が単語の種類数となり、大きくなりすぎる。(2)全ての単語の距離が等距離となり、単語の意味の近さが表現できないという問題点があります。\n",
    "\n",
    "そこで、一般に数万次元からなるone-hotベクトルを100～200次元程度の密な（値を持つ次元の数が多い）ベクトルに変換し、情報圧縮を行います。この操作をword2vecと呼びます。\n",
    "\n",
    "参考サイト  \n",
    "[Word2Vec：発明した本人も驚く単語ベクトルの驚異的な力](https://deepage.net/bigdata/machine_learning/2016/09/02/word2vec_power_of_word_vector.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備\n",
    "\n",
    "1. Anaconda Navigatorからgensimをインストール\n",
    "\n",
    "2. word2vecのWikipediaでの学習済みモデルをダウンロード・展開し、entity_vector.model.binファイルをカレントディレクトリに置いておきます。\n",
    "http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html)の使い方\n",
    "\n",
    "単語とベクトルの対応を記録しておけるデータ構造であるKeyedVectorsを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('entity_vector.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語ベクトルの空間で、意味の近いものを求めてみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('高波', 0.7870876789093018),\n",
       " ('大雨', 0.7866235375404358),\n",
       " ('[台風]', 0.7853839993476868),\n",
       " ('強風', 0.7827271223068237),\n",
       " ('豪雨', 0.780258297920227),\n",
       " ('暴風雨', 0.780162513256073),\n",
       " ('集中豪雨', 0.7598928213119507),\n",
       " ('暴風', 0.7581937313079834),\n",
       " ('[集中豪雨]', 0.7475163340568542),\n",
       " ('[大雨]', 0.7466163635253906)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('台風')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトルの引き算を行うことで、関係を抽出することができます。たとえば、「パリ」から「フランス」を引き算することで「首都」という関係が得られたと考えられるので、「日本」にこの「首都」という関係を足すと、「東京」が得られると期待できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[日本]', 0.6431803703308105),\n",
       " ('東京', 0.6326844692230225),\n",
       " ('[東京]', 0.6148374080657959),\n",
       " ('日本国内', 0.5847295522689819),\n",
       " ('大阪', 0.5656222105026245),\n",
       " ('都内', 0.5597203373908997),\n",
       " ('東京都内', 0.5482653975486755),\n",
       " ('[大阪]', 0.5426324605941772),\n",
       " ('神戸', 0.520367443561554),\n",
       " ('[横浜]', 0.5199853181838989)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['パリ','日本'], negative=['フランス'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('焼き肉', 0.5954942107200623),\n",
       " ('うどん', 0.5942089557647705),\n",
       " ('コロッケ', 0.5901445150375366),\n",
       " ('牛丼', 0.5884590148925781),\n",
       " ('カツ', 0.5824934840202332),\n",
       " ('ネギ', 0.5817806720733643),\n",
       " ('おでん', 0.5800793170928955),\n",
       " ('パフェ', 0.5788909196853638),\n",
       " ('おにぎり', 0.5777252912521362),\n",
       " ('焼肉', 0.5764982104301453)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['たこ焼き','香川'], negative=['大阪'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Doc2Vec\n",
    "\n",
    "文や文章をベクトル化して、類似度計算を可能にします。\n",
    "\n",
    "参考サイト  \n",
    "[Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル](https://deepage.net/machine_learning/2017/01/08/doc2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.2527516186237335),\n",
       " (3, 0.2247992753982544),\n",
       " (4, 0.15878286957740784),\n",
       " (8, 0.06908675283193588),\n",
       " (7, 0.04946136474609375),\n",
       " (5, -0.005576267838478088),\n",
       " (6, -0.006039753556251526),\n",
       " (0, -0.1989622712135315)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "m = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "sentences = [\n",
    "    \"２時にアラームをセット\",\n",
    "    \"アラームを３時に設定\",\n",
    "    \"５時になったら知らせて\",\n",
    "    \"アラームを使いたい\",\n",
    "    \"３０分後に起こして\",\n",
    "    \"２時に京都に着きたい\",\n",
    "    \"乗換案内を起動\",\n",
    "    \"京都から東京までの新幹線\",\n",
    "    \"東京行きの最終電車\",\n",
    "]\n",
    "\n",
    "# 空のリストを作成（学習データとなる各文書を格納）\n",
    "X = []\n",
    "for s, t in zip(sentences, range(len(sentences))):\n",
    "    X.append(TaggedDocument(words=m.parse(s).split(), tags=[t]))   \n",
    "\n",
    "# 学習\n",
    "# documents:学習データ（TaggedDocumentのリスト）\n",
    "# min_count: 学習に使用する単語の最低出現回数\n",
    "# dm:学習モデル 0:DBOW, 1:DM（デフォルト)\n",
    "model = Doc2Vec(documents=X, min_count=1, dm=1)\n",
    " \n",
    "# 学習したモデルを保存\n",
    "model.save('doc2vec.model')\n",
    "\n",
    "# 検索\n",
    "model.docvecs.most_similar([2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
